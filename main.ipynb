{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.models.model_selection import GridSearch, FeatureSelection\n",
    "from src.models.classification import Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader= yaml.SafeLoader)\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.260648</td>\n",
       "      <td>-0.469648</td>\n",
       "      <td>2.496266</td>\n",
       "      <td>-0.083724</td>\n",
       "      <td>0.129681</td>\n",
       "      <td>0.732898</td>\n",
       "      <td>0.519014</td>\n",
       "      <td>-0.130006</td>\n",
       "      <td>0.727159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>0.217606</td>\n",
       "      <td>-0.134794</td>\n",
       "      <td>0.165959</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>-0.434824</td>\n",
       "      <td>-0.081230</td>\n",
       "      <td>-0.151045</td>\n",
       "      <td>17982.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.985100</td>\n",
       "      <td>-0.356045</td>\n",
       "      <td>0.558056</td>\n",
       "      <td>-0.429654</td>\n",
       "      <td>0.277140</td>\n",
       "      <td>0.428605</td>\n",
       "      <td>0.406466</td>\n",
       "      <td>-0.133118</td>\n",
       "      <td>0.347452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194936</td>\n",
       "      <td>-0.605761</td>\n",
       "      <td>0.079469</td>\n",
       "      <td>-0.577395</td>\n",
       "      <td>0.190090</td>\n",
       "      <td>0.296503</td>\n",
       "      <td>-0.248052</td>\n",
       "      <td>-0.064512</td>\n",
       "      <td>6531.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.260272</td>\n",
       "      <td>-0.949385</td>\n",
       "      <td>1.728538</td>\n",
       "      <td>-0.457986</td>\n",
       "      <td>0.074062</td>\n",
       "      <td>1.419481</td>\n",
       "      <td>0.743511</td>\n",
       "      <td>-0.095576</td>\n",
       "      <td>-0.261297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.702906</td>\n",
       "      <td>0.945045</td>\n",
       "      <td>-1.154666</td>\n",
       "      <td>-0.605564</td>\n",
       "      <td>-0.312895</td>\n",
       "      <td>-0.300258</td>\n",
       "      <td>-0.244718</td>\n",
       "      <td>2513.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.152152</td>\n",
       "      <td>-0.508959</td>\n",
       "      <td>1.746840</td>\n",
       "      <td>-1.090178</td>\n",
       "      <td>0.249486</td>\n",
       "      <td>1.143312</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>-0.065130</td>\n",
       "      <td>-0.205698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146927</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.214048</td>\n",
       "      <td>-1.893131</td>\n",
       "      <td>1.003963</td>\n",
       "      <td>-0.515950</td>\n",
       "      <td>-0.165316</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>5384.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.206820</td>\n",
       "      <td>-0.165280</td>\n",
       "      <td>1.527053</td>\n",
       "      <td>-0.448293</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.530549</td>\n",
       "      <td>0.658849</td>\n",
       "      <td>-0.212660</td>\n",
       "      <td>1.049921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106984</td>\n",
       "      <td>0.729727</td>\n",
       "      <td>-0.161666</td>\n",
       "      <td>0.312561</td>\n",
       "      <td>-0.414116</td>\n",
       "      <td>1.071126</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.419117</td>\n",
       "      <td>14278.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0 -0.260648 -0.469648  2.496266 -0.083724  0.129681  0.732898  0.519014   \n",
       "1   1  0.985100 -0.356045  0.558056 -0.429654  0.277140  0.428605  0.406466   \n",
       "2   2 -0.260272 -0.949385  1.728538 -0.457986  0.074062  1.419481  0.743511   \n",
       "3   3 -0.152152 -0.508959  1.746840 -1.090178  0.249486  1.143312  0.518269   \n",
       "4   4 -0.206820 -0.165280  1.527053 -0.448293  0.106125  0.530549  0.658849   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0 -0.130006  0.727159  ... -0.110552  0.217606 -0.134794  0.165959  0.126280   \n",
       "1 -0.133118  0.347452  ... -0.194936 -0.605761  0.079469 -0.577395  0.190090   \n",
       "2 -0.095576 -0.261297  ... -0.005020  0.702906  0.945045 -1.154666 -0.605564   \n",
       "3 -0.065130 -0.205698  ... -0.146927 -0.038212 -0.214048 -1.893131  1.003963   \n",
       "4 -0.212660  1.049921  ... -0.106984  0.729727 -0.161666  0.312561 -0.414116   \n",
       "\n",
       "        V26       V27       V28    Amount  Class  \n",
       "0 -0.434824 -0.081230 -0.151045  17982.10      0  \n",
       "1  0.296503 -0.248052 -0.064512   6531.37      0  \n",
       "2 -0.312895 -0.300258 -0.244718   2513.54      0  \n",
       "3 -0.515950 -0.165316  0.048424   5384.44      0  \n",
       "4  1.071126  0.023712  0.419117  14278.97      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(config['data_loader']['path'])\n",
    "display(df.head())\n",
    "\n",
    "# split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.iloc[:,1:-1], df['Class']\n",
    "    , test_size=config['model_selection']['test_set_size']\n",
    "    , random_state=123\n",
    "    , shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearch(\n",
    "    hyper_params=config['model_selection']['algorithms']\n",
    "    , cv=config['model_selection']['cross_validator']\n",
    "    , scoring_metric=config['model_selection']['scoring_metric']\n",
    ")\n",
    "grid_search.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy feature selection\n",
    "feature_selection = FeatureSelection(X=X_train, y=y_train)\n",
    "feature_selection.wrapper(\n",
    "    algorithm='LogisticRegression'\n",
    "    , algorithm_params={'max_iter': 100}\n",
    "    , tolerance=config['model_selection']['tolerance']\n",
    "    , cv=config['model_selection']['cross_validator']\n",
    "    , scoring_metric=config['model_selection']['scoring_metric']\n",
    ")\n",
    "\n",
    "# should feature selection be done before or after model selection?\n",
    "# should it be trained on different dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gonpr\\ML_Projects\\Fraud\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# fit best algorithm on most important features of training data \n",
    "clf = Classification(\n",
    "    algorithm='LogisticRegression', #**grid_search.best_hyperparams\n",
    "    )\n",
    "clf.fit(X=X_train.iloc[100000:, :], y=y_train.iloc[100000:,])\n",
    "# predict target value for the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "y_score = clf.score(X_test)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gonpr\\ML_Projects\\Fraud\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gonpr\\ML_Projects\\Fraud\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gonpr\\ML_Projects\\Fraud\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gonpr\\ML_Projects\\Fraud\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gonpr\\ML_Projects\\Fraud\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gonpr\\ML_Projects\\Fraud\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.4545454545376217)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.model_selection import ClassificationThreshold\n",
    "\n",
    "tuned_clf = ClassificationThreshold(\n",
    "    scoring_metric=\"f1\"\n",
    "    , cv=5\n",
    ")\n",
    "tuned_clf.fit(clf=clf, X=X_train.iloc[:100000, :], y=y_train.iloc[:100000,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(15, 7))\n",
    "axs.plot(\n",
    "        tuned_clf.cv_results_[\"thresholds\"],\n",
    "        tuned_clf.cv_results_[\"scores\"],\n",
    "        color=\"tab:orange\",\n",
    "    )\n",
    "axs.plot(\n",
    "    tuned_clf.best_threshold_,\n",
    "    tuned_clf.best_score_,\n",
    "    \"o\",\n",
    "    markersize=10,\n",
    "    color=\"tab:orange\",\n",
    "    label=\"Optimal cut-off point for the business metric\",\n",
    ")\n",
    "axs.legend()\n",
    "axs.set_xlabel(\"Decision threshold (probability)\")\n",
    "axs.set_ylabel(\"Objective score (using cost-matrix)\")\n",
    "axs.set_title(\"Objective score as a function of the decision threshold\")\n",
    "\"\"\"\n",
    "https://medium.com/towards-data-science/tune-in-decision-threshold-optimization-with-scikit-learns-tunedthresholdclassifiercv-7de558a2cf58\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_cost_sensitive_learning.html#tunedthresholdclassifiercv-no-cv\n",
    "https://scikit-learn.org/stable/modules/classification_threshold.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pos_label, neg_label = y_train.unique()\n",
    "\n",
    "def fpr_score(y, y_pred, neg_label, pos_label):\n",
    "    cm = confusion_matrix(y, y_pred, labels=[neg_label, pos_label])\n",
    "    tn, fp, _, _ = cm.ravel()\n",
    "    tnr = tn / (tn + fp)\n",
    "    return 1 - tnr\n",
    "\n",
    "tpr_score = recall_score  # TPR and recall are the same metric\n",
    "scoring = {\n",
    "    \"precision\": make_scorer(precision_score, pos_label=pos_label),\n",
    "    \"recall\": make_scorer(recall_score, pos_label=pos_label),\n",
    "    \"fpr\": make_scorer(fpr_score, neg_label=neg_label, pos_label=pos_label),\n",
    "    \"tpr\": make_scorer(tpr_score, pos_label=pos_label),\n",
    "}\n",
    "\n",
    "def plot_roc_pr_curves(vanilla_model, tuned_model, *, title):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(21, 6))\n",
    "\n",
    "    linestyles = (\"dashed\", \"dotted\")\n",
    "    markerstyles = (\"o\", \">\")\n",
    "    colors = (\"tab:blue\", \"tab:orange\")\n",
    "    names = (\"Vanilla GBDT\", \"Tuned GBDT\")\n",
    "    for idx, (est, linestyle, marker, color, name) in enumerate(\n",
    "        zip((vanilla_model, tuned_model), linestyles, markerstyles, colors, names)\n",
    "    ):\n",
    "        decision_threshold = getattr(est, \"best_threshold_\", 0.5)\n",
    "        PrecisionRecallDisplay.from_estimator(\n",
    "            est,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            pos_label=pos_label,\n",
    "            linestyle=linestyle,\n",
    "            color=color,\n",
    "            ax=axs[0],\n",
    "            name=name,\n",
    "        )\n",
    "        axs[0].plot(\n",
    "            scoring[\"recall\"](est, X_test, y_test),\n",
    "            scoring[\"precision\"](est, X_test, y_test),\n",
    "            marker,\n",
    "            markersize=10,\n",
    "            color=color,\n",
    "            label=f\"Cut-off point at probability of {decision_threshold:.2f}\",\n",
    "        )\n",
    "        RocCurveDisplay.from_estimator(\n",
    "            est,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            pos_label=pos_label,\n",
    "            linestyle=linestyle,\n",
    "            color=color,\n",
    "            ax=axs[1],\n",
    "            name=name,\n",
    "            plot_chance_level=idx == 1,\n",
    "        )\n",
    "        axs[1].plot(\n",
    "            scoring[\"fpr\"](est, X_test, y_test),\n",
    "            scoring[\"tpr\"](est, X_test, y_test),\n",
    "            marker,\n",
    "            markersize=10,\n",
    "            color=color,\n",
    "            label=f\"Cut-off point at probability of {decision_threshold:.2f}\",\n",
    "        )\n",
    "\n",
    "    axs[0].set_title(\"Precision-Recall curve\")\n",
    "    axs[0].legend()\n",
    "    axs[1].set_title(\"ROC curve\")\n",
    "    axs[1].legend()\n",
    "\n",
    "    axs[2].plot(\n",
    "        tuned_model.cv_results_[\"thresholds\"],\n",
    "        tuned_model.cv_results_[\"scores\"],\n",
    "        color=\"tab:orange\",\n",
    "    )\n",
    "    axs[2].plot(\n",
    "        tuned_model.best_threshold_,\n",
    "        tuned_model.best_score_,\n",
    "        \"o\",\n",
    "        markersize=10,\n",
    "        color=\"tab:orange\",\n",
    "        label=\"Optimal cut-off point for the business metric\",\n",
    "    )\n",
    "    axs[2].legend()\n",
    "    axs[2].set_xlabel(\"Decision threshold (probability)\")\n",
    "    axs[2].set_ylabel(\"Objective score (using cost-matrix)\")\n",
    "    axs[2].set_title(\"Objective score as a function of the decision threshold\")\n",
    "    fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Title 123!\"\n",
    "plot_roc_pr_curves(clf.model, tuned_clf, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visuals.boundary import plot_boundary\n",
    "\n",
    "plot_boundary(\n",
    "    X=X_test.iloc[:,[3,6,8]], y=y_test, clf=clf, azim=50, plot_points=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame({'score': y_score, 'label': y_pred}).groupby(by=['label']).describe()\n",
    "#print(clf.model.decision_path(X_test[best_features[:2]].iloc[:10,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, RocCurveDisplay,\n",
    "    precision_recall_curve, PrecisionRecallDisplay, average_precision_score\n",
    ")\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\n",
    "    f\"\"\"Accuracy : {round(accuracy_score(y_test, y_pred), 5)}\n",
    "Precision: {round(precision_score(y_test, y_pred), 5)}\n",
    "Recall   : {round(recall_score(y_test, y_pred), 5)}\n",
    "F1-Score : {round(f1_score(y_test, y_pred), 5)}\"\"\"\n",
    ")\n",
    "\n",
    "# plot ROC and PR curves\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "# plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "ax[0].plot(fpr, tpr, color=\"blue\", lw=2, label=f\"ROC Curve (AUC = {roc_auc:.3f})\")\n",
    "ax[0].plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\", lw=2, label=\"Random Guessing\")\n",
    "ax[0].set_xlabel(\"False Positive Rate\")\n",
    "ax[0].set_ylabel(\"True Positive Rate\")\n",
    "ax[0].set_title(\"ROC Curve\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "\n",
    "# plot PR curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "ap_score = average_precision_score(y_test, y_score)\n",
    "ax[1].plot(recall, precision, color=\"green\", lw=2, label=f\"PR Curve (AP = {ap_score:.3f})\")\n",
    "ax[1].set_xlabel(\"Recall\")\n",
    "ax[1].set_ylabel(\"Precision\")\n",
    "ax[1].set_title(\"Precision-Recall Curve\")\n",
    "ax[1].legend(loc=\"lower left\")\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "overfitting\n",
    "\n",
    "https://scikit-learn.org/stable/modules/learning_curve.html\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
