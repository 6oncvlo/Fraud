{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "\n",
    "from src.data.prepare_data import prepare_data\n",
    "from src.models.utils import train_splits, imbalanced_sampling\n",
    "from src.models.tuner import HyperParamSearch, LabelWeightSearch\n",
    "from src.models.model import Classifier\n",
    "from src.models.evaluation import Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader= yaml.SafeLoader)\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>amount</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time        v1        v2        v3        v4        v5        v6        v7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         v8        v9  ...       v21       v22       v23       v24       v25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        v26       v27       v28  amount  label  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and prepare data\n",
    "df = pd.read_csv(config['data_loader']['path'])\n",
    "df = prepare_data(df=df)\n",
    "display(df.head())\n",
    "\n",
    "# check class distributions\n",
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and Test Set**\n",
    "- Split whole set into train and test sets using strat sampling\n",
    "- Apply oversampling as the number of positive instances is small\n",
    "- Split whole train set into multiple train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.iloc[:,:-1], df['label']\n",
    "    , test_size=config['train_test_split']['test_size']\n",
    "    , random_state=123\n",
    "    , shuffle=True\n",
    "    , stratify=df['label']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    0.998274\n",
      "1    0.001726\n",
      "Name: proportion, dtype: float64 label\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# apply oversampling to the train set\n",
    "X_train_rs, y_train_rs = imbalanced_sampling(\n",
    "    method='over'\n",
    "    , X_train=X_train\n",
    "    , y_train=y_train\n",
    ")\n",
    "\n",
    "# check class distributions\n",
    "print(\n",
    "    y_train.value_counts(normalize=True)\n",
    "    , y_train_rs.value_counts(normalize=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train sets into multiple sets\n",
    "train = train_splits(X_train_rs, y_train_rs, config['train_test_split'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimization**\n",
    "- Hyper-parameters - search which hyper-parameters optimize scoring metric for the given algorithm\n",
    "- sample_weight - search optimal weights for labels in order to optimize scoring metric\n",
    "\n",
    "To avoid overfitting, these optimizations are done in different training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 17:15:41,915] A new study created in memory with name: no-name-7b21ffcd-ae70-4c13-8060-fba768c8d90c\n",
      "[I 2025-06-09 17:15:50,898] Trial 0 finished with value: 0.9996297652452274 and parameters: {'n_estimators': 39, 'max_depth': 20, 'learning_rate': 0.36626497696389115, 'gamma': 5.986584841970366, 'subsample': 0.5780093202212182}. Best is trial 0 with value: 0.9996297652452274.\n",
      "[I 2025-06-09 17:15:58,974] Trial 1 finished with value: 0.9963272693985885 and parameters: {'n_estimators': 17, 'max_depth': 4, 'learning_rate': 0.43322189674169265, 'gamma': 6.011150117432088, 'subsample': 0.8540362888980227}. Best is trial 0 with value: 0.9996297652452274.\n",
      "[I 2025-06-09 17:16:04,584] Trial 2 finished with value: 0.9987449052491364 and parameters: {'n_estimators': 4, 'max_depth': 20, 'learning_rate': 0.41638887775941047, 'gamma': 2.1233911067827616, 'subsample': 0.5909124836035503}. Best is trial 0 with value: 0.9996297652452274.\n",
      "[I 2025-06-09 17:16:12,041] Trial 3 finished with value: 0.9995001834031836 and parameters: {'n_estimators': 20, 'max_depth': 8, 'learning_rate': 0.2628534593844867, 'gamma': 4.319450186421157, 'subsample': 0.645614570099021}. Best is trial 0 with value: 0.9996297652452274.\n",
      "[I 2025-06-09 17:16:26,562] Trial 4 finished with value: 0.9991706745111875 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.14678017961907386, 'gamma': 3.663618432936917, 'subsample': 0.728034992108518}. Best is trial 0 with value: 0.9996297652452274.\n",
      "[I 2025-06-09 17:16:43,019] Trial 5 finished with value: 0.9995964445956901 and parameters: {'n_estimators': 79, 'max_depth': 6, 'learning_rate': 0.2576029847683922, 'gamma': 5.924145688620425, 'subsample': 0.5232252063599989}. Best is trial 0 with value: 0.9996297652452274.\n",
      "[I 2025-06-09 17:16:56,371] Trial 6 finished with value: 0.9965049832761752 and parameters: {'n_estimators': 62, 'max_depth': 6, 'learning_rate': 0.033460744899654477, 'gamma': 9.488855372533333, 'subsample': 0.9828160165372797}. Best is trial 0 with value: 0.9996297652452274.\n",
      "[I 2025-06-09 17:17:20,578] Trial 7 finished with value: 0.9993928156244941 and parameters: {'n_estimators': 82, 'max_depth': 8, 'learning_rate': 0.049738384889185555, 'gamma': 6.842330265121569, 'subsample': 0.7200762468698007}. Best is trial 0 with value: 0.9996297652452274.\n",
      "[I 2025-06-09 17:17:27,782] Trial 8 finished with value: 0.9966271625094079 and parameters: {'n_estimators': 14, 'max_depth': 11, 'learning_rate': 0.018159872036493982, 'gamma': 9.093204020787821, 'subsample': 0.6293899908000085}. Best is trial 0 with value: 0.9996297652452274.\n",
      "[I 2025-06-09 17:17:44,925] Trial 9 finished with value: 0.9996297657249904 and parameters: {'n_estimators': 67, 'max_depth': 8, 'learning_rate': 0.2605139425677276, 'gamma': 5.4671027934327965, 'subsample': 0.5924272277627636}. Best is trial 9 with value: 0.9996297657249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      " - params: {'n_estimators': 67, 'max_depth': 8, 'learning_rate': 0.2605139425677276, 'gamma': 5.4671027934327965, 'subsample': 0.5924272277627636}\n",
      " - score: 0.9996297657249904 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set tuner for hyperparam optimization\n",
    "tuner = HyperParamSearch(config=config['optimization'], algorithm=\"XGBClassifier\")\n",
    "\n",
    "def objective(trial) -> float:\n",
    "    return tuner.fit(X=train[1].iloc[:,:-1], y=train[1].iloc[:,-1], trial=trial)\n",
    "\n",
    "# set study\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\n",
    "    f\"Best trial:\\n\",\n",
    "    f\"- params: {study.best_trial.params}\\n\",\n",
    "    f\"- score: {study.best_trial.value}\", \"\\n\"*2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 17:17:44,967] A new study created in memory with name: no-name-a20a0046-be0d-4ced-9fe3-8646d2d4794e\n",
      "[I 2025-06-09 17:18:06,402] Trial 0 finished with value: 0.999906 and parameters: {'weight_0': 38, 'weight_1': 96}. Best is trial 0 with value: 0.999906.\n",
      "[I 2025-06-09 17:18:27,570] Trial 1 finished with value: 0.9999100000000001 and parameters: {'weight_0': 74, 'weight_1': 60}. Best is trial 1 with value: 0.9999100000000001.\n",
      "[I 2025-06-09 17:18:50,296] Trial 2 finished with value: 0.9998800000000001 and parameters: {'weight_0': 16, 'weight_1': 16}. Best is trial 1 with value: 0.9999100000000001.\n",
      "[I 2025-06-09 17:19:11,771] Trial 3 finished with value: 0.999718 and parameters: {'weight_0': 6, 'weight_1': 87}. Best is trial 1 with value: 0.9999100000000001.\n",
      "[I 2025-06-09 17:19:28,921] Trial 4 finished with value: 0.999886 and parameters: {'weight_0': 61, 'weight_1': 71}. Best is trial 1 with value: 0.9999100000000001.\n",
      "[I 2025-06-09 17:19:42,564] Trial 5 finished with value: 0.99964 and parameters: {'weight_0': 3, 'weight_1': 97}. Best is trial 1 with value: 0.9999100000000001.\n",
      "[I 2025-06-09 17:19:58,208] Trial 6 finished with value: 0.9999399999999999 and parameters: {'weight_0': 84, 'weight_1': 22}. Best is trial 6 with value: 0.9999399999999999.\n",
      "[I 2025-06-09 17:20:19,528] Trial 7 finished with value: 0.9998999999999999 and parameters: {'weight_0': 19, 'weight_1': 19}. Best is trial 6 with value: 0.9999399999999999.\n",
      "[I 2025-06-09 17:20:39,382] Trial 8 finished with value: 0.9998999999999999 and parameters: {'weight_0': 31, 'weight_1': 53}. Best is trial 6 with value: 0.9999399999999999.\n",
      "[I 2025-06-09 17:20:56,473] Trial 9 finished with value: 0.9999119999999999 and parameters: {'weight_0': 44, 'weight_1': 30}. Best is trial 6 with value: 0.9999399999999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      " - params: {'weight_0': 84, 'weight_1': 22}\n",
      " - score: 0.9999399999999999 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set label weight tuner using previous study\n",
    "tuner = LabelWeightSearch(\n",
    "    config = config[\"optimization\"],\n",
    "    estimator=Classifier(algorithm=\"XGBClassifier\", **study.best_trial.params)\n",
    ")\n",
    "\n",
    "def objective(trial) -> float:\n",
    "    return tuner.fit(X=train[2].iloc[:,:-1], y=train[2].iloc[:,-1], trial=trial)\n",
    "\n",
    "# set study\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\n",
    "    f\"Best trial:\\n\",\n",
    "    f\"- params: {study.best_trial.params}\\n\",\n",
    "    f\"- score: {study.best_trial.value}\", \"\\n\"*2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.99951</td>\n",
       "      <td>0.90909</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.85106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy  precision  recall  f1_score\n",
       "dataset                                       \n",
       "train     1.00000    1.00000     1.0   1.00000\n",
       "test      0.99951    0.90909     0.8   0.85106"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set algorithm best hyperparams and sample weight\n",
    "class_weights = {int(key[-1]): value for key, value in study.best_trial.params.items()}\n",
    "sample_weight = np.array([class_weights[class_id] for class_id in y_train_rs])\n",
    "hyperparams = (\n",
    "    config[\"optimization\"][\"param_grid\"][\"XGBClassifier\"][\"fixed\"]\n",
    "    | tuner.model.model.get_params()\n",
    ")\n",
    "\n",
    "# fit model on whole training set\n",
    "clf = Classifier(algorithm=\"XGBClassifier\", **hyperparams)\n",
    "clf.fit(X=X_train_rs, y=y_train_rs, sample_weight=sample_weight)\n",
    "\n",
    "# test set evaluation\n",
    "eval = Evaluation(clf=clf, threshold=0.5)\n",
    "eval.fit(\n",
    "    train=(X_train_rs, y_train_rs),\n",
    "    test=(X_test, y_test)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
