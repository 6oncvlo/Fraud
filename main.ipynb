{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.data.prepare_data import prepare_data\n",
    "from src.data.utils import resample_data\n",
    "from src.models.utils import train_splits, imbalanced_sampling\n",
    "from src.models.model_selection import GridSearch\n",
    "from src.models.classification import Classification\n",
    "from src.models.feature_selection import FeatureSelection\n",
    "from src.models.evaluation import Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader= yaml.SafeLoader)\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "df = pd.read_csv(config['data_loader']['path'])\n",
    "df = prepare_data(df=df)\n",
    "display(df.head())\n",
    "\n",
    "# resample for imbalanced sets\n",
    "df_sampled = resample_data(df=df, pos_share=0.01)\n",
    "\n",
    "# check class distributions\n",
    "print(\n",
    "    df['label'].value_counts(normalize=True)\n",
    "    , df_sampled['label'].value_counts(normalize=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sampled.iloc[:,:-1], df_sampled['label']\n",
    "    , test_size=config['train_test_split']['test_size']\n",
    "    , random_state=123\n",
    "    , shuffle=True\n",
    "    , stratify=df_sampled['label']\n",
    "    )\n",
    "\n",
    "# check class distributions\n",
    "print(\n",
    "    y_train.value_counts(normalize=True)\n",
    "    , y_test.value_counts(normalize=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply oversampling to the train set\n",
    "X_train_rs, y_train_rs = imbalanced_sampling(\n",
    "    method='over'\n",
    "    , X_train=X_train\n",
    "    , y_train=y_train\n",
    ")\n",
    "\n",
    "# check class distributions\n",
    "print(\n",
    "    y_train.value_counts(normalize=True)\n",
    "    , y_train_rs.value_counts(normalize=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train sets into multiple sets and check class distributions\n",
    "train = train_splits(X_train_rs, y_train_rs, config['train_test_split'])\n",
    "[train[i].iloc[:,-1].value_counts(normalize=True) for i in train.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search best algorithm and hyperparams\n",
    "grid_search = GridSearch(config=config['optimization'])\n",
    "grid_search.fit(X=train[1].iloc[:,:-1], y=train[1].iloc[:,-1])\n",
    "\n",
    "for j in grid_search.results.keys():\n",
    "    print(j, '-', grid_search.results[j]['best_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy feature selection\n",
    "clf = Classification(\n",
    "    algorithm=grid_search.best_algorithm\n",
    "    , **grid_search.best_hyperparams\n",
    "    )\n",
    "\n",
    "feature_selection = FeatureSelection(X=train[2].iloc[:,:-1], y=train[2].iloc[:,-1])\n",
    "feats = feature_selection.wrapper(clf=clf, config=config['optimization'])\n",
    "\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit best algorithm on most important features of training data \n",
    "clf = Classification(\n",
    "    algorithm=grid_search.best_algorithm\n",
    "    , **grid_search.best_hyperparams\n",
    "    )\n",
    "clf.fit(X=X_train_rs[feats], y=y_train_rs)\n",
    "\n",
    "# test set evaluation\n",
    "eval = Evaluation(clf=clf, threshold=0.5)\n",
    "eval.fit(\n",
    "    X_train=X_train_rs[feats], y_train=y_train_rs\n",
    "    , X_test=X_test[feats], y_test=y_test\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
